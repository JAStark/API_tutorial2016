{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Allows a provider to control what information you have access to, and how you access the data.**\n",
    "* **Check any Terms of Use associated with the API**\n",
    "* **Also check Rate Limits -> How many times you can ping their server (usually per hour)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll be collecting data from http://opendata.dc.gov/datasets/dc3289eab3d2400ea49c154863312434_8 which is a DC Crime dataset of crime in the last 30 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, import all the things you need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json              # Most API's provide data as a json file, \n",
    "import csv               # So we can save and read csv\n",
    "import requests          # To access the API\n",
    "import pandas as pd      # So we can work with the data in a dataframe\n",
    "import time              # So we can control time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate output csv file\n",
    "* Next, we call into being a new .csv file, and assign it to the variable `'output_filename'`\n",
    "* Then open the file using the `'csv'` module we imported above, and give it write privileges\n",
    "* Last, we write in some column headers. These are the fields we want to fetch from the json. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_filename = 'ipython_foo.csv'\n",
    "fileWriter = csv.writer(open(output_filename, \"w+\"),delimiter=\",\")\n",
    "fileWriter.writerow(['anc', 'census_tract', 'coords', 'district', 'method', 'objectid', 'offense', 'report_time', 'shift', 'ward'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab raw JSON data from the API\n",
    "* Assign the API URL to a variable name\n",
    "* Using the requests module we imported, get the 30-day data \n",
    "* Let the code sleep for 5 seconds to allow time for the response to come back\n",
    "* Check the response code:\n",
    "    * for reference, response codes:  http://www.restapitutorial.com/httpstatuscodes.html\n",
    "* Read in the response and assign it to a variable `'data'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the response status:  None\n"
     ]
    }
   ],
   "source": [
    "crime_incidents_30day_url = 'http://opendata.dc.gov/datasets/dc3289eab3d2400ea49c154863312434_8.geojson'\n",
    "\n",
    "response = requests.get(crime_incidents_30day_url)\n",
    "time.sleep(5)\n",
    "\n",
    "print(\"\\nThis is the response status: \", response.raise_for_status())\n",
    "\n",
    "data = json.loads(response.text) #r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['type', 'features'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The JSON is a nested dictionary: the nest we care about is the `'features'` nest, so lets grab that part and assign it to data (essentially overwriting the first `'data'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore a little bit\n",
    "* Now we can look to see what keys we have this `'features'` subset:\n",
    "    - We have `'type'`, `'geometry'` and `'properties'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'geometry': {'coordinates': [-76.9975579843, 38.909409767], 'type': 'Point'},\n",
       " 'properties': {'ANC': '5D',\n",
       "  'BLOCKSITEADDRESS': '1300 - 1399 BLOCK OF 5TH STREET NE',\n",
       "  'BLOCKXCOORD': 400212,\n",
       "  'BLOCKYCOORD': 137949,\n",
       "  'BLOCK_GROUP': '008803 1',\n",
       "  'BUSINESSIMPROVEMENTDISTRICT': None,\n",
       "  'CCN': '16089057',\n",
       "  'CENSUS_TRACT': '008803',\n",
       "  'DISTRICT': 'FIFTH',\n",
       "  'END_DATE': '2016-06-01T20:50:01.000Z',\n",
       "  'LASTMODIFIEDDATE': '2016-06-03T08:32:14.000Z',\n",
       "  'METHOD': 'OTHERS',\n",
       "  'NEIGHBORHOODCLUSTER': '23',\n",
       "  'OBJECTID': 193290,\n",
       "  'OFFENSE': 'THEFT F/AUTO',\n",
       "  'PSA': '506',\n",
       "  'REPORTDATETIME': '2016-06-02T17:03:13.000Z',\n",
       "  'SHIFT': 'EVENING',\n",
       "  'START_DATE': '2016-06-01T13:50:25.000Z',\n",
       "  'VOTING_PRECINCT': 'Precinct 76',\n",
       "  'WARD': '5'},\n",
       " 'type': 'Feature'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]   # what kind of data do we have in the first record?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** How does this break down?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['geometry', 'type', 'properties'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()  # Top level keys are 'geometry' and 'properties'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['type', 'coordinates'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['geometry'].keys()    # keys inside 'geometry' are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['BLOCK_GROUP', 'START_DATE', 'DISTRICT', 'CENSUS_TRACT', 'BLOCKYCOORD', 'BLOCKXCOORD', 'OFFENSE', 'ANC', 'SHIFT', 'END_DATE', 'METHOD', 'VOTING_PRECINCT', 'BLOCKSITEADDRESS', 'BUSINESSIMPROVEMENTDISTRICT', 'CCN', 'NEIGHBORHOODCLUSTER', 'WARD', 'LASTMODIFIEDDATE', 'PSA', 'OBJECTID', 'REPORTDATETIME'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['properties'].keys()  # keys inside 'properties' are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organising the JSON into columns we want\n",
    "* The columns need to be extracted in the same order as we have in our csv that we created in the beginning:\n",
    "    - On the left we have the csv columns names - in lower case so we dont get confused\n",
    "    - On the right we have the JSON column names that we handpicked after inspected the data above\n",
    "\n",
    "* We will read in this function first, so we can call it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_json_fields(data, i):\n",
    "\n",
    "    row_data = {}\n",
    "\n",
    "    row_data['anc'] = data[i]['properties']['ANC']\n",
    "    row_data['census_tract'] = data[i]['properties']['CENSUS_TRACT']\n",
    "    row_data['coords'] = data[i]['geometry']['coordinates']\n",
    "    row_data['district'] = data[i]['properties']['DISTRICT']\n",
    "    row_data['method'] = data[i]['properties']['METHOD']\n",
    "    row_data['objectid'] = data[i]['properties']['OBJECTID']\n",
    "    row_data['offense'] = data[i]['properties']['OFFENSE']\n",
    "    row_data['report_time'] = data[i]['properties']['REPORTDATETIME']\n",
    "    row_data['shift'] = data[i]['properties']['SHIFT']\n",
    "    row_data['ward'] = data[i]['properties']['WARD']\n",
    "\n",
    "    return row_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracted these colums\n",
    "* Now we can call the function:\n",
    "    - First we make an empty list to store each row or record of data\n",
    "    - Then we say \"for each record in the JSON (i), run the `'get_data'` function, and put the neat result in the `'data_list'` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "        \n",
    "for i in range(len(data)):\n",
    "    data_list.append(get_json_fields(data, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Best check we have data in our list:\n",
    "    - How many records is it?\n",
    "    - What does the first record look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3035"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anc': '5D',\n",
       " 'census_tract': '008803',\n",
       " 'coords': [-76.9975579843, 38.909409767],\n",
       " 'district': 'FIFTH',\n",
       " 'method': 'OTHERS',\n",
       " 'objectid': 193290,\n",
       " 'offense': 'THEFT F/AUTO',\n",
       " 'report_time': '2016-06-02T17:03:13.000Z',\n",
       " 'shift': 'EVENING',\n",
       " 'ward': '5'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Great! Now we can make the list into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDF = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anc</th>\n",
       "      <th>census_tract</th>\n",
       "      <th>coords</th>\n",
       "      <th>district</th>\n",
       "      <th>method</th>\n",
       "      <th>objectid</th>\n",
       "      <th>offense</th>\n",
       "      <th>report_time</th>\n",
       "      <th>shift</th>\n",
       "      <th>ward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5D</td>\n",
       "      <td>008803</td>\n",
       "      <td>[-76.9975579843, 38.909409767]</td>\n",
       "      <td>FIFTH</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>193290</td>\n",
       "      <td>THEFT F/AUTO</td>\n",
       "      <td>2016-06-02T17:03:13.000Z</td>\n",
       "      <td>EVENING</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3E</td>\n",
       "      <td>001001</td>\n",
       "      <td>[-77.0853018915, 38.9599152513]</td>\n",
       "      <td>SECOND</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>193291</td>\n",
       "      <td>THEFT/OTHER</td>\n",
       "      <td>2016-06-02T17:39:32.000Z</td>\n",
       "      <td>EVENING</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5C</td>\n",
       "      <td>009102</td>\n",
       "      <td>[-76.9819666406, 38.9219389949]</td>\n",
       "      <td>FIFTH</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>193292</td>\n",
       "      <td>ROBBERY</td>\n",
       "      <td>2016-06-02T17:50:50.000Z</td>\n",
       "      <td>EVENING</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5D</td>\n",
       "      <td>008904</td>\n",
       "      <td>[-76.9741901124, 38.9014976093]</td>\n",
       "      <td>FIFTH</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>193293</td>\n",
       "      <td>THEFT/OTHER</td>\n",
       "      <td>2016-06-02T18:02:32.000Z</td>\n",
       "      <td>EVENING</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6B</td>\n",
       "      <td>007000</td>\n",
       "      <td>[-76.9955880526, 38.8827269275]</td>\n",
       "      <td>FIRST</td>\n",
       "      <td>OTHERS</td>\n",
       "      <td>193294</td>\n",
       "      <td>THEFT F/AUTO</td>\n",
       "      <td>2016-06-02T18:04:42.000Z</td>\n",
       "      <td>EVENING</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  anc census_tract                           coords district  method  \\\n",
       "0  5D       008803   [-76.9975579843, 38.909409767]    FIFTH  OTHERS   \n",
       "1  3E       001001  [-77.0853018915, 38.9599152513]   SECOND  OTHERS   \n",
       "2  5C       009102  [-76.9819666406, 38.9219389949]    FIFTH  OTHERS   \n",
       "3  5D       008904  [-76.9741901124, 38.9014976093]    FIFTH  OTHERS   \n",
       "4  6B       007000  [-76.9955880526, 38.8827269275]    FIRST  OTHERS   \n",
       "\n",
       "   objectid       offense               report_time    shift ward  \n",
       "0    193290  THEFT F/AUTO  2016-06-02T17:03:13.000Z  EVENING    5  \n",
       "1    193291   THEFT/OTHER  2016-06-02T17:39:32.000Z  EVENING    3  \n",
       "2    193292       ROBBERY  2016-06-02T17:50:50.000Z  EVENING    5  \n",
       "3    193293   THEFT/OTHER  2016-06-02T18:02:32.000Z  EVENING    5  \n",
       "4    193294  THEFT F/AUTO  2016-06-02T18:04:42.000Z  EVENING    6  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF.head()   # 'head()' just cos we only want to see the first few records to check it's ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append this data to our existing CSV file\n",
    "* We created the CSV with our desired column headers already -> now we want to add the data\n",
    "* The 'a' opens the file in 'append' mode\n",
    "* Probably dont need the 'a' in both the `'open'` and the `'dataDF.to_csv'` lines, but hey!\n",
    "* Header is False, cos we already have one\n",
    "* Index is false, cos we dont want to add the Index column which is automatically created in Pandas dataframes to our CSV - all our columns will get thrown off!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(output_filename, 'a') as f:\n",
    "    dataDF.to_csv(f, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If appending data, we should check we have no duplicates\n",
    "* Since this is only 30 days, we might want to run the collection regularly to get updated information.\n",
    "* Rather than creating a new file every time, we can just append the data to our existing file\n",
    "* We could collect every 30 days and maybe not have any duplicates, but we might miss some records if our collection time is a little off\n",
    "* We could collect every 29 days and not miss any data, but we might end up with duplicates. \n",
    "* Or, you could collect every _day_ to get daily updates\n",
    "    - Here is a function `'drop_duplicates'` that keeps only the first record if a record is duplicated so that order is preserved (this may or may not be important, depending on what you're doing)\n",
    "    \n",
    "#### weird thing:\n",
    "* Running drop_duplicates here in ipython notebook with `'temp.to_csv(output_filename, header=False, index=False)'` leads to a missing header (no column names). When run in spyder, I dont have this problem. Good thing we dont need to remove the header when we append to the existing csv so as not to duplicate the header row, since we are already removing duplicates :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_duplicates(output_filename):\n",
    "        temp = pd.read_csv(output_filename)\n",
    "        temp.drop_duplicates(keep='first', inplace=True)\n",
    "        temp.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_duplicates(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPROVEMENTS\n",
    "#### Dealing with duplicates\n",
    "\n",
    "* A record can be updated when new information comes in, leading to a new record line with only the `'objectid'` being duplicated\n",
    "* If this is the case, you'll want to keep the `'_last_'` duplicate, as this will the updated one\n",
    "* Also if this is the case, you'll want to check duplicates based _only_ on the `'objectid'` column, as this is the only column that will not be updated.\n",
    "* There is a way to `'drop_duplicates'` in pandas based on whether there is duplication in a specifed column (eg `'objectid'` but this resulted in a keyerror for me...I'll need to figure it out :(\n",
    "\n",
    "#### Collected pre-filtered 30-day data\n",
    "* The API allows you to grab filtered JSON data. Potentially, you could use this to only gather data beginning where your previous collection left off - no duplicates! OR collect only incidents involving a gun. However, when I attempted this, the API `'response'` was a 202, meaning it was accepted, but the data itself was pending...so if my requests connection stays open (only if I'm running off a server) I might receive the data within 24 hours? Who knows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduling to run automatically every given number of hours/minutes/seconds..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at  [scheduled_API_code.py](http/...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
